{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anwishn/project/blob/main/Ensemble_Model_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSeAMmiKpQlK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.utils import load_img, img_to_array\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.models import Model, Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.regularizers import l2\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4M_YOg5vrZpD"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Function to preprocess images\n",
        "def preprocess_image(image_path, target_size=(299, 299)):\n",
        "    image = load_img(image_path, target_size=target_size)\n",
        "    image = img_to_array(image)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    image = preprocess_input(image)  # Use preprocess_input from InceptionV3\n",
        "    return image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heJaNx-QsGzn"
      },
      "outputs": [],
      "source": [
        "# Function to extract features using VGG16\n",
        "def extract_features(img_array, model):\n",
        "    features = model.predict(img_array)\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-0LQ6AHsIKQ"
      },
      "outputs": [],
      "source": [
        "# # Load the pre-trained VGG16 model for feature extraction\n",
        "# base_model = VGG16(weights='imagenet')\n",
        "# feature_model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc1').output)\n",
        "\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "inception_model = InceptionV3(weights='imagenet')\n",
        "feature_model = Model(inputs=inception_model.input, outputs=inception_model.get_layer('mixed10').output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQrtDusrsKaY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "081d75d0-e1e2-4cc8-9089-141e2b7116b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive to access the dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsen6KDTsPVV"
      },
      "outputs": [],
      "source": [
        "# Define the dataset directories\n",
        "base_dir = '/content/drive/MyDrive'\n",
        "chanterelle_dir = os.path.join(base_dir, 'chanterelle')\n",
        "non_chanterelle_dir = os.path.join(base_dir, 'non-chanterelle')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhZVcq3TsaME",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4211e97-c8a4-49f9-d0f3-6e3d3c9d9476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 248ms/step\n",
            "1/1 [==============================] - 0s 261ms/step\n",
            "1/1 [==============================] - 0s 415ms/step\n",
            "1/1 [==============================] - 0s 466ms/step\n",
            "1/1 [==============================] - 0s 479ms/step\n",
            "1/1 [==============================] - 0s 483ms/step\n",
            "1/1 [==============================] - 0s 447ms/step\n",
            "1/1 [==============================] - 0s 468ms/step\n",
            "1/1 [==============================] - 0s 481ms/step\n",
            "1/1 [==============================] - 0s 440ms/step\n",
            "1/1 [==============================] - 0s 454ms/step\n",
            "1/1 [==============================] - 0s 478ms/step\n",
            "1/1 [==============================] - 0s 431ms/step\n",
            "1/1 [==============================] - 0s 401ms/step\n",
            "1/1 [==============================] - 0s 251ms/step\n",
            "1/1 [==============================] - 0s 250ms/step\n",
            "1/1 [==============================] - 0s 249ms/step\n",
            "1/1 [==============================] - 0s 245ms/step\n",
            "1/1 [==============================] - 0s 253ms/step\n",
            "1/1 [==============================] - 0s 289ms/step\n",
            "1/1 [==============================] - 0s 371ms/step\n",
            "1/1 [==============================] - 0s 252ms/step\n",
            "1/1 [==============================] - 0s 253ms/step\n",
            "1/1 [==============================] - 0s 253ms/step\n",
            "1/1 [==============================] - 0s 253ms/step\n",
            "1/1 [==============================] - 0s 249ms/step\n",
            "1/1 [==============================] - 0s 257ms/step\n",
            "1/1 [==============================] - 0s 252ms/step\n",
            "1/1 [==============================] - 0s 245ms/step\n",
            "1/1 [==============================] - 0s 252ms/step\n",
            "1/1 [==============================] - 0s 240ms/step\n",
            "1/1 [==============================] - 0s 258ms/step\n",
            "1/1 [==============================] - 0s 249ms/step\n",
            "1/1 [==============================] - 0s 258ms/step\n",
            "1/1 [==============================] - 0s 249ms/step\n",
            "1/1 [==============================] - 0s 251ms/step\n",
            "1/1 [==============================] - 0s 271ms/step\n",
            "1/1 [==============================] - 0s 247ms/step\n",
            "1/1 [==============================] - 0s 250ms/step\n",
            "1/1 [==============================] - 0s 258ms/step\n",
            "1/1 [==============================] - 0s 253ms/step\n",
            "1/1 [==============================] - 0s 288ms/step\n",
            "1/1 [==============================] - 0s 455ms/step\n",
            "1/1 [==============================] - 0s 481ms/step\n",
            "1/1 [==============================] - 0s 450ms/step\n",
            "1/1 [==============================] - 0s 459ms/step\n",
            "1/1 [==============================] - 0s 451ms/step\n",
            "1/1 [==============================] - 0s 484ms/step\n",
            "1/1 [==============================] - 0s 452ms/step\n",
            "1/1 [==============================] - 0s 466ms/step\n",
            "1/1 [==============================] - 0s 453ms/step\n",
            "1/1 [==============================] - 0s 414ms/step\n",
            "1/1 [==============================] - 0s 251ms/step\n",
            "1/1 [==============================] - 0s 243ms/step\n",
            "1/1 [==============================] - 0s 259ms/step\n",
            "1/1 [==============================] - 0s 244ms/step\n",
            "1/1 [==============================] - 0s 250ms/step\n",
            "1/1 [==============================] - 0s 266ms/step\n",
            "1/1 [==============================] - 0s 243ms/step\n",
            "1/1 [==============================] - 0s 245ms/step\n",
            "1/1 [==============================] - 0s 248ms/step\n",
            "1/1 [==============================] - 0s 245ms/step\n",
            "1/1 [==============================] - 0s 251ms/step\n",
            "1/1 [==============================] - 0s 267ms/step\n",
            "1/1 [==============================] - 0s 253ms/step\n",
            "1/1 [==============================] - 0s 246ms/step\n",
            "1/1 [==============================] - 0s 264ms/step\n",
            "1/1 [==============================] - 0s 247ms/step\n",
            "1/1 [==============================] - 0s 249ms/step\n",
            "1/1 [==============================] - 0s 261ms/step\n",
            "1/1 [==============================] - 0s 263ms/step\n",
            "1/1 [==============================] - 0s 251ms/step\n",
            "1/1 [==============================] - 0s 255ms/step\n",
            "1/1 [==============================] - 0s 250ms/step\n",
            "1/1 [==============================] - 0s 276ms/step\n",
            "1/1 [==============================] - 0s 264ms/step\n",
            "1/1 [==============================] - 0s 246ms/step\n",
            "1/1 [==============================] - 0s 254ms/step\n",
            "1/1 [==============================] - 0s 259ms/step\n",
            "1/1 [==============================] - 0s 247ms/step\n",
            "1/1 [==============================] - 0s 246ms/step\n",
            "1/1 [==============================] - 0s 440ms/step\n",
            "1/1 [==============================] - 0s 475ms/step\n",
            "1/1 [==============================] - 0s 449ms/step\n",
            "1/1 [==============================] - 0s 488ms/step\n",
            "1/1 [==============================] - 0s 451ms/step\n",
            "1/1 [==============================] - 0s 482ms/step\n",
            "1/1 [==============================] - 0s 436ms/step\n",
            "1/1 [==============================] - 0s 460ms/step\n",
            "1/1 [==============================] - 0s 451ms/step\n",
            "1/1 [==============================] - 0s 448ms/step\n",
            "1/1 [==============================] - 0s 353ms/step\n",
            "1/1 [==============================] - 0s 253ms/step\n",
            "1/1 [==============================] - 0s 253ms/step\n",
            "1/1 [==============================] - 0s 263ms/step\n",
            "1/1 [==============================] - 0s 256ms/step\n",
            "1/1 [==============================] - 0s 248ms/step\n",
            "1/1 [==============================] - 0s 263ms/step\n",
            "1/1 [==============================] - 0s 250ms/step\n",
            "1/1 [==============================] - 0s 252ms/step\n",
            "1/1 [==============================] - 0s 247ms/step\n",
            "1/1 [==============================] - 0s 256ms/step\n",
            "1/1 [==============================] - 0s 256ms/step\n",
            "1/1 [==============================] - 0s 246ms/step\n",
            "1/1 [==============================] - 0s 250ms/step\n",
            "1/1 [==============================] - 0s 250ms/step\n",
            "1/1 [==============================] - 0s 247ms/step\n",
            "1/1 [==============================] - 0s 251ms/step\n",
            "1/1 [==============================] - 0s 260ms/step\n",
            "1/1 [==============================] - 0s 251ms/step\n",
            "1/1 [==============================] - 0s 247ms/step\n",
            "1/1 [==============================] - 0s 256ms/step\n",
            "1/1 [==============================] - 0s 248ms/step\n",
            "1/1 [==============================] - 0s 260ms/step\n",
            "1/1 [==============================] - 0s 248ms/step\n",
            "1/1 [==============================] - 0s 247ms/step\n",
            "1/1 [==============================] - 0s 262ms/step\n",
            "1/1 [==============================] - 0s 251ms/step\n",
            "1/1 [==============================] - 0s 246ms/step\n",
            "1/1 [==============================] - 0s 273ms/step\n",
            "1/1 [==============================] - 0s 252ms/step\n",
            "1/1 [==============================] - 0s 257ms/step\n",
            "1/1 [==============================] - 0s 448ms/step\n",
            "1/1 [==============================] - 0s 439ms/step\n",
            "1/1 [==============================] - 0s 449ms/step\n",
            "1/1 [==============================] - 0s 480ms/step\n",
            "1/1 [==============================] - 0s 455ms/step\n",
            "1/1 [==============================] - 0s 445ms/step\n",
            "1/1 [==============================] - 0s 434ms/step\n",
            "1/1 [==============================] - 0s 481ms/step\n",
            "1/1 [==============================] - 0s 459ms/step\n",
            "1/1 [==============================] - 0s 424ms/step\n",
            "1/1 [==============================] - 0s 245ms/step\n",
            "1/1 [==============================] - 0s 247ms/step\n",
            "1/1 [==============================] - 0s 263ms/step\n",
            "1/1 [==============================] - 0s 251ms/step\n",
            "1/1 [==============================] - 0s 249ms/step\n",
            "1/1 [==============================] - 0s 261ms/step\n",
            "1/1 [==============================] - 0s 253ms/step\n",
            "1/1 [==============================] - 0s 252ms/step\n",
            "1/1 [==============================] - 0s 252ms/step\n",
            "1/1 [==============================] - 0s 245ms/step\n",
            "1/1 [==============================] - 0s 262ms/step\n",
            "1/1 [==============================] - 0s 254ms/step\n",
            "1/1 [==============================] - 0s 262ms/step\n",
            "1/1 [==============================] - 0s 259ms/step\n",
            "1/1 [==============================] - 0s 248ms/step\n",
            "1/1 [==============================] - 0s 254ms/step\n",
            "1/1 [==============================] - 0s 263ms/step\n",
            "1/1 [==============================] - 0s 255ms/step\n",
            "1/1 [==============================] - 0s 252ms/step\n",
            "1/1 [==============================] - 0s 262ms/step\n",
            "1/1 [==============================] - 0s 248ms/step\n",
            "1/1 [==============================] - 0s 252ms/step\n",
            "1/1 [==============================] - 0s 269ms/step\n",
            "1/1 [==============================] - 0s 243ms/step\n",
            "1/1 [==============================] - 0s 252ms/step\n",
            "1/1 [==============================] - 0s 262ms/step\n",
            "1/1 [==============================] - 0s 250ms/step\n",
            "1/1 [==============================] - 0s 247ms/step\n",
            "1/1 [==============================] - 0s 378ms/step\n",
            "1/1 [==============================] - 0s 466ms/step\n",
            "1/1 [==============================] - 0s 444ms/step\n",
            "1/1 [==============================] - 0s 469ms/step\n",
            "1/1 [==============================] - 0s 433ms/step\n",
            "1/1 [==============================] - 0s 449ms/step\n",
            "1/1 [==============================] - 0s 454ms/step\n",
            "1/1 [==============================] - 0s 428ms/step\n",
            "1/1 [==============================] - 0s 462ms/step\n",
            "1/1 [==============================] - 0s 415ms/step\n",
            "1/1 [==============================] - 0s 428ms/step\n",
            "1/1 [==============================] - 0s 256ms/step\n",
            "1/1 [==============================] - 0s 258ms/step\n",
            "1/1 [==============================] - 0s 244ms/step\n",
            "1/1 [==============================] - 0s 255ms/step\n",
            "1/1 [==============================] - 0s 265ms/step\n",
            "1/1 [==============================] - 0s 250ms/step\n",
            "1/1 [==============================] - 0s 248ms/step\n",
            "1/1 [==============================] - 0s 252ms/step\n",
            "1/1 [==============================] - 0s 256ms/step\n",
            "1/1 [==============================] - 0s 255ms/step\n",
            "1/1 [==============================] - 0s 247ms/step\n",
            "1/1 [==============================] - 0s 250ms/step\n",
            "1/1 [==============================] - 0s 250ms/step\n",
            "1/1 [==============================] - 0s 248ms/step\n",
            "1/1 [==============================] - 0s 249ms/step\n",
            "1/1 [==============================] - 0s 253ms/step\n",
            "1/1 [==============================] - 0s 245ms/step\n",
            "1/1 [==============================] - 0s 245ms/step\n",
            "1/1 [==============================] - 0s 249ms/step\n",
            "1/1 [==============================] - 1s 503ms/step\n",
            "1/1 [==============================] - 0s 457ms/step\n",
            "1/1 [==============================] - 0s 246ms/step\n",
            "1/1 [==============================] - 0s 245ms/step\n",
            "1/1 [==============================] - 0s 261ms/step\n",
            "1/1 [==============================] - 0s 243ms/step\n",
            "1/1 [==============================] - 0s 242ms/step\n",
            "1/1 [==============================] - 0s 343ms/step\n",
            "1/1 [==============================] - 0s 427ms/step\n",
            "1/1 [==============================] - 0s 460ms/step\n",
            "1/1 [==============================] - 0s 446ms/step\n",
            "1/1 [==============================] - 0s 463ms/step\n",
            "1/1 [==============================] - 0s 477ms/step\n",
            "1/1 [==============================] - 0s 446ms/step\n",
            "1/1 [==============================] - 0s 448ms/step\n",
            "1/1 [==============================] - 0s 442ms/step\n",
            "1/1 [==============================] - 0s 429ms/step\n",
            "1/1 [==============================] - 0s 249ms/step\n",
            "1/1 [==============================] - 0s 253ms/step\n",
            "1/1 [==============================] - 0s 267ms/step\n",
            "1/1 [==============================] - 0s 265ms/step\n",
            "1/1 [==============================] - 0s 250ms/step\n",
            "1/1 [==============================] - 0s 250ms/step\n",
            "1/1 [==============================] - 0s 241ms/step\n",
            "1/1 [==============================] - 0s 245ms/step\n",
            "1/1 [==============================] - 0s 247ms/step\n",
            "1/1 [==============================] - 0s 249ms/step\n",
            "1/1 [==============================] - 0s 253ms/step\n",
            "1/1 [==============================] - 0s 246ms/step\n",
            "1/1 [==============================] - 0s 249ms/step\n",
            "1/1 [==============================] - 0s 266ms/step\n",
            "1/1 [==============================] - 0s 248ms/step\n",
            "1/1 [==============================] - 0s 248ms/step\n",
            "1/1 [==============================] - 0s 266ms/step\n",
            "1/1 [==============================] - 0s 246ms/step\n",
            "1/1 [==============================] - 0s 250ms/step\n",
            "1/1 [==============================] - 0s 257ms/step\n",
            "1/1 [==============================] - 0s 250ms/step\n",
            "1/1 [==============================] - 0s 249ms/step\n",
            "1/1 [==============================] - 0s 259ms/step\n",
            "1/1 [==============================] - 0s 249ms/step\n",
            "1/1 [==============================] - 0s 245ms/step\n",
            "1/1 [==============================] - 0s 260ms/step\n",
            "1/1 [==============================] - 0s 248ms/step\n",
            "1/1 [==============================] - 0s 246ms/step\n",
            "1/1 [==============================] - 0s 409ms/step\n",
            "1/1 [==============================] - 0s 467ms/step\n",
            "1/1 [==============================] - 0s 480ms/step\n",
            "1/1 [==============================] - 0s 461ms/step\n",
            "1/1 [==============================] - 0s 479ms/step\n",
            "1/1 [==============================] - 0s 434ms/step\n",
            "1/1 [==============================] - 0s 465ms/step\n",
            "1/1 [==============================] - 0s 460ms/step\n",
            "1/1 [==============================] - 0s 444ms/step\n",
            "1/1 [==============================] - 0s 255ms/step\n",
            "1/1 [==============================] - 0s 258ms/step\n",
            "1/1 [==============================] - 0s 271ms/step\n",
            "1/1 [==============================] - 0s 263ms/step\n",
            "1/1 [==============================] - 0s 266ms/step\n",
            "1/1 [==============================] - 0s 271ms/step\n",
            "1/1 [==============================] - 0s 258ms/step\n",
            "1/1 [==============================] - 0s 257ms/step\n",
            "1/1 [==============================] - 0s 274ms/step\n",
            "1/1 [==============================] - 0s 261ms/step\n",
            "1/1 [==============================] - 0s 258ms/step\n",
            "1/1 [==============================] - 0s 265ms/step\n",
            "1/1 [==============================] - 0s 252ms/step\n",
            "1/1 [==============================] - 0s 255ms/step\n",
            "1/1 [==============================] - 0s 260ms/step\n",
            "1/1 [==============================] - 0s 257ms/step\n",
            "1/1 [==============================] - 0s 256ms/step\n",
            "1/1 [==============================] - 0s 245ms/step\n",
            "1/1 [==============================] - 0s 254ms/step\n",
            "1/1 [==============================] - 0s 261ms/step\n",
            "1/1 [==============================] - 0s 250ms/step\n",
            "1/1 [==============================] - 0s 249ms/step\n",
            "1/1 [==============================] - 0s 255ms/step\n",
            "1/1 [==============================] - 0s 262ms/step\n",
            "1/1 [==============================] - 0s 251ms/step\n",
            "1/1 [==============================] - 0s 247ms/step\n",
            "1/1 [==============================] - 0s 252ms/step\n",
            "1/1 [==============================] - 0s 259ms/step\n",
            "1/1 [==============================] - 0s 452ms/step\n",
            "1/1 [==============================] - 0s 483ms/step\n",
            "1/1 [==============================] - 0s 462ms/step\n",
            "1/1 [==============================] - 0s 492ms/step\n",
            "1/1 [==============================] - 0s 445ms/step\n",
            "1/1 [==============================] - 0s 497ms/step\n",
            "1/1 [==============================] - 0s 432ms/step\n",
            "1/1 [==============================] - 0s 476ms/step\n",
            "1/1 [==============================] - 0s 469ms/step\n",
            "1/1 [==============================] - 0s 408ms/step\n",
            "1/1 [==============================] - 0s 446ms/step\n",
            "1/1 [==============================] - 0s 247ms/step\n",
            "1/1 [==============================] - 0s 247ms/step\n",
            "1/1 [==============================] - 0s 249ms/step\n",
            "1/1 [==============================] - 0s 252ms/step\n",
            "1/1 [==============================] - 0s 248ms/step\n",
            "1/1 [==============================] - 0s 252ms/step\n",
            "1/1 [==============================] - 0s 266ms/step\n",
            "1/1 [==============================] - 0s 259ms/step\n",
            "1/1 [==============================] - 0s 252ms/step\n",
            "1/1 [==============================] - 0s 249ms/step\n",
            "1/1 [==============================] - 0s 264ms/step\n",
            "1/1 [==============================] - 0s 252ms/step\n",
            "1/1 [==============================] - 0s 250ms/step\n",
            "1/1 [==============================] - 0s 260ms/step\n",
            "1/1 [==============================] - 0s 255ms/step\n",
            "1/1 [==============================] - 0s 248ms/step\n",
            "1/1 [==============================] - 0s 261ms/step\n",
            "1/1 [==============================] - 0s 257ms/step\n",
            "1/1 [==============================] - 0s 248ms/step\n",
            "1/1 [==============================] - 0s 268ms/step\n",
            "1/1 [==============================] - 0s 247ms/step\n",
            "1/1 [==============================] - 0s 248ms/step\n",
            "1/1 [==============================] - 0s 260ms/step\n",
            "1/1 [==============================] - 0s 254ms/step\n",
            "1/1 [==============================] - 0s 250ms/step\n",
            "1/1 [==============================] - 0s 266ms/step\n",
            "1/1 [==============================] - 0s 246ms/step\n",
            "1/1 [==============================] - 0s 253ms/step\n",
            "1/1 [==============================] - 0s 315ms/step\n",
            "1/1 [==============================] - 0s 426ms/step\n",
            "1/1 [==============================] - 0s 483ms/step\n",
            "1/1 [==============================] - 0s 458ms/step\n",
            "1/1 [==============================] - 0s 451ms/step\n",
            "1/1 [==============================] - 0s 472ms/step\n",
            "1/1 [==============================] - 0s 447ms/step\n",
            "1/1 [==============================] - 0s 439ms/step\n",
            "1/1 [==============================] - 0s 467ms/step\n",
            "1/1 [==============================] - 0s 449ms/step\n",
            "1/1 [==============================] - 0s 430ms/step\n",
            "1/1 [==============================] - 0s 248ms/step\n",
            "1/1 [==============================] - 0s 272ms/step\n",
            "1/1 [==============================] - 0s 250ms/step\n",
            "1/1 [==============================] - 0s 250ms/step\n",
            "1/1 [==============================] - 0s 260ms/step\n",
            "1/1 [==============================] - 0s 252ms/step\n",
            "1/1 [==============================] - 0s 244ms/step\n",
            "1/1 [==============================] - 0s 258ms/step\n",
            "1/1 [==============================] - 0s 253ms/step\n",
            "1/1 [==============================] - 0s 249ms/step\n",
            "1/1 [==============================] - 0s 261ms/step\n",
            "1/1 [==============================] - 0s 250ms/step\n",
            "1/1 [==============================] - 0s 247ms/step\n",
            "1/1 [==============================] - 0s 263ms/step\n",
            "1/1 [==============================] - 0s 249ms/step\n",
            "1/1 [==============================] - 0s 249ms/step\n",
            "1/1 [==============================] - 0s 269ms/step\n"
          ]
        }
      ],
      "source": [
        "# Extract features for each image and create labels\n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "# Process chanterelle images\n",
        "for image_path in os.listdir(chanterelle_dir):\n",
        "    img = preprocess_image(os.path.join(chanterelle_dir, image_path))\n",
        "    feat = extract_features(img, feature_model)\n",
        "    features.append(feat.flatten())\n",
        "    labels.append(1)  # Chanterelle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3ePANHosc9a"
      },
      "outputs": [],
      "source": [
        "# Process non-chanterelle images\n",
        "for image_path in os.listdir(non_chanterelle_dir):\n",
        "    img = preprocess_image(os.path.join(non_chanterelle_dir, image_path))\n",
        "    feat = extract_features(img, feature_model)\n",
        "    features.append(feat.flatten())\n",
        "    labels.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIeC3QqLuJfJ"
      },
      "outputs": [],
      "source": [
        "# Convert to numpy arrays\n",
        "features = np.array(features)\n",
        "labels = np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWO_rsc4vmPH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31ab11a3-e3dc-4f24-e5bc-0a81c63b3a31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (272, 131072)\n",
            "Test data shape: (68, 131072)\n"
          ]
        }
      ],
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42, stratify=labels)\n",
        "\n",
        "# Output the shapes of the split data\n",
        "print(f'Training data shape: {X_train.shape}')\n",
        "print(f'Test data shape: {X_test.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNbrQ19jvppg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe505c38-64f0-4bce-ad9f-f9063cac1248"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "4/4 [==============================] - 19s 3s/step - loss: 2.6645 - accuracy: 0.4378 - val_loss: 6.8277 - val_accuracy: 0.0909\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 14s 4s/step - loss: 2.9004 - accuracy: 0.5346 - val_loss: 6.2125 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 11s 3s/step - loss: 3.3525 - accuracy: 0.4793 - val_loss: 6.1539 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 7s 2s/step - loss: 3.5586 - accuracy: 0.5161 - val_loss: 6.7521 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 6s 1s/step - loss: 3.6557 - accuracy: 0.6129 - val_loss: 6.8502 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 9s 2s/step - loss: 3.8206 - accuracy: 0.5668 - val_loss: 6.5401 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 9s 2s/step - loss: 3.9038 - accuracy: 0.6083 - val_loss: 5.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 12s 3s/step - loss: 3.7417 - accuracy: 0.6083 - val_loss: 5.3200 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 9s 2s/step - loss: 3.7706 - accuracy: 0.6359 - val_loss: 4.5724 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 11s 3s/step - loss: 3.6598 - accuracy: 0.6866 - val_loss: 4.1758 - val_accuracy: 0.0909\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 12s 4s/step - loss: 3.5995 - accuracy: 0.6636 - val_loss: 3.8105 - val_accuracy: 0.3091\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 10s 3s/step - loss: 3.4331 - accuracy: 0.6866 - val_loss: 3.5157 - val_accuracy: 0.4909\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 11s 3s/step - loss: 3.4498 - accuracy: 0.7051 - val_loss: 3.2865 - val_accuracy: 0.6727\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 14s 4s/step - loss: 3.2790 - accuracy: 0.6636 - val_loss: 3.1002 - val_accuracy: 0.8364\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 9s 2s/step - loss: 3.2088 - accuracy: 0.6959 - val_loss: 2.9720 - val_accuracy: 0.8909\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 11s 3s/step - loss: 3.0682 - accuracy: 0.7097 - val_loss: 2.8768 - val_accuracy: 0.9636\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 11s 3s/step - loss: 3.0083 - accuracy: 0.7097 - val_loss: 2.8058 - val_accuracy: 0.9818\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 9s 2s/step - loss: 2.9496 - accuracy: 0.7604 - val_loss: 2.6873 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 15s 4s/step - loss: 2.8311 - accuracy: 0.7419 - val_loss: 2.6041 - val_accuracy: 0.9818\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 10s 3s/step - loss: 2.7065 - accuracy: 0.7926 - val_loss: 2.5547 - val_accuracy: 0.9818\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 9s 3s/step - loss: 2.7032 - accuracy: 0.7650 - val_loss: 2.4709 - val_accuracy: 0.9818\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 11s 3s/step - loss: 2.5242 - accuracy: 0.8387 - val_loss: 2.3801 - val_accuracy: 0.9818\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 13s 4s/step - loss: 2.5407 - accuracy: 0.8157 - val_loss: 2.2975 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 9s 2s/step - loss: 2.4321 - accuracy: 0.8249 - val_loss: 2.2253 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 12s 3s/step - loss: 2.4322 - accuracy: 0.8295 - val_loss: 2.1706 - val_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "def create_nn_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Dense(512, activation='relu', kernel_regularizer=l2(0.001), input_shape=(input_shape,)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(256, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create and train the neural network\n",
        "nn_model = create_nn_model(X_train.shape[1])\n",
        "\n",
        "\n",
        "# Create a callback that saves the best model\n",
        "checkpoint_cb = ModelCheckpoint(\"best_model.h5\", save_best_only=True)\n",
        "\n",
        "# Create early stopping callback\n",
        "early_stopping_cb = EarlyStopping(patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train the model with callbacks\n",
        "nn_history = nn_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=25,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[checkpoint_cb, early_stopping_cb]\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5aHXCMbwU_U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "135e842a-f4c9-4669-e084-f6a42d68fa88"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-d5915ebd878d>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Create and train the SVM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msvm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msvm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Evaluate the SVM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    199\u001b[0m             )\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         sample_weight = np.asarray(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_validate_targets\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    750\u001b[0m                 \u001b[0;34m\"The number of classes has to be greater than one; got %d class\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m                 \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The number of classes has to be greater than one; got 1 class"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Create and train the SVM\n",
        "svm_model = SVC(kernel='linear', probability=True)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the SVM\n",
        "svm_accuracy = accuracy_score(y_test, svm_model.predict(X_test))\n",
        "print(f'SVM Test Accuracy: {svm_accuracy}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDSFci-iiAdt"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Example for SVM\n",
        "param_grid_svm = {'C': [0.1, 1, 10], 'gamma': ['scale', 0.001, 0.01], 'kernel': ['rbf', 'linear']}\n",
        "grid_search_svm = GridSearchCV(SVC(), param_grid_svm, cv=5, scoring='accuracy')\n",
        "grid_search_svm.fit(X_train, y_train)\n",
        "best_svm_model = grid_search_svm.best_estimator_\n",
        "\n",
        "# Example for Random Forest\n",
        "param_grid_rf = {'n_estimators': [100, 200, 300], 'max_features': ['auto', 'sqrt'], 'max_depth': [4, 6, 8]}\n",
        "grid_search_rf = GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=5, scoring='accuracy')\n",
        "grid_search_rf.fit(X_train, y_train)\n",
        "best_rf_model = grid_search_rf.best_estimator_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOEkodgDwZNY"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, X, y, iterations=5):\n",
        "    scores = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
        "    for i in range(iterations):\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        scores['accuracy'].append(accuracy_score(y_test, predictions))\n",
        "        scores['precision'].append(precision_score(y_test, predictions))\n",
        "        scores['recall'].append(recall_score(y_test, predictions))\n",
        "        scores['f1'].append(f1_score(y_test, predictions))\n",
        "    return scores\n",
        "\n",
        "# Use the function for both SVM and Random Forest\n",
        "svm_scores = evaluate_model(best_svm_model, X_train, y_train)\n",
        "rf_scores = evaluate_model(best_rf_model, X_train, y_train)\n",
        "\n",
        "# Visualization can be done similarly to how accuracy and loss were visualized,\n",
        "# but now you would have multiple points per metric to plot for each iteration.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cMBjZgYwevJ"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUVCzlLpwnSp"
      },
      "outputs": [],
      "source": [
        "nn_model.save('nn_model.h5')\n",
        "# Save other models using joblib for sklearn models\n",
        "import joblib\n",
        "joblib.dump(svm_model, 'svm_model.pkl')\n",
        "joblib.dump(rf_model, 'rf_model.pkl')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0d99mzNYxjEA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# nn_history is the return value from the model.fit call\n",
        "history_dict = nn_history.history\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_dict['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history_dict['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_dict['loss'], label='Training Loss')\n",
        "plt.plot(history_dict['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQ2Js4zGiAdu"
      },
      "outputs": [],
      "source": [
        "nn_history.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jummBn9m1MrN"
      },
      "outputs": [],
      "source": [
        "# For SVM\n",
        "svm_predictions = svm_model.predict(X_test)\n",
        "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
        "svm_precision = precision_score(y_test, svm_predictions)\n",
        "svm_recall = recall_score(y_test, svm_predictions)\n",
        "svm_f1 = f1_score(y_test, svm_predictions)\n",
        "\n",
        "# For Random Forest\n",
        "rf_predictions = rf_model.predict(X_test)\n",
        "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
        "rf_precision = precision_score(y_test, rf_predictions)\n",
        "rf_recall = recall_score(y_test, rf_predictions)\n",
        "rf_f1 = f1_score(y_test, rf_predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwlvTO9v1sA0"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# SVM Confusion Matrix\n",
        "plt.subplot(1, 2, 1)\n",
        "svm_cm = confusion_matrix(y_test, svm_predictions)\n",
        "sns.heatmap(svm_cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('SVM Confusion Matrix')\n",
        "plt.ylabel('Actual Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "\n",
        "# Random Forest Confusion Matrix\n",
        "plt.subplot(1, 2, 2)\n",
        "rf_cm = confusion_matrix(y_test, rf_predictions)\n",
        "sns.heatmap(rf_cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Random Forest Confusion Matrix')\n",
        "plt.ylabel('Actual Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgxIR6Iu1y3Q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
